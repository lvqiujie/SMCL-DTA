#!/usr/bin/env python3
"""
è®ºæ–‡æ ‡å‡†å¤ç°è„šæœ¬
ç”¨äºç”Ÿæˆè®ºæ–‡ä¸­æŠ¥å‘Šçš„æ ‡å‡†åŒ–ç»“æœ
ç¡®ä¿å…¶ä»–ç ”ç©¶è€…èƒ½å¤Ÿç²¾ç¡®å¤ç°æˆ‘ä»¬çš„å‘ç°
"""

import os
import torch
import numpy as np
import random
import json
from datetime import datetime
from torch_geometric.data import DataLoader
from sklearn.isotonic import IsotonicRegression

from metrics import get_cindex, get_rm2
from dataset import *
from model_0428_16_dual import MGraphDTA

def set_all_seeds(seed=42):
    """è®¾ç½®æ‰€æœ‰éšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)

class PaperStandardReproduction:
    """è®ºæ–‡æ ‡å‡†å¤ç°å™¨"""
    
    def __init__(self, device='cpu'):
        self.device = torch.device(device)
        self.results = {}
        
        # è®ºæ–‡ä¸­ä½¿ç”¨çš„æœ€ä½³æ¨¡å‹é…ç½®
        self.best_models_config = [
            {
                'name': 'epoch_1344_best',
                'path': 'save/20250725_233313_kiba/model/epoch-1344, LR-0.000009, MSEloss-0.1232, cindex-0.8529, r2-0.7146, test1: [MSEloss-0.1328, cindex:0.8885, r2:0.7805].pt',
                'paper_performance': {'mse': 0.1328, 'cindex': 0.8885, 'r2': 0.7805}
            },
            {
                'name': 'epoch_1323_second', 
                'path': 'save/20250725_233313_kiba/model/epoch-1323, LR-0.000011, MSEloss-0.1231, cindex-0.8546, r2-0.7115, test1: [MSEloss-0.1329, cindex:0.8884, r2:0.7780].pt',
                'paper_performance': {'mse': 0.1329, 'cindex': 0.8884, 'r2': 0.7780}
            },
            {
                'name': 'epoch_1400_third',
                'path': 'save/20250725_233313_kiba/model/epoch-1400, LR-0.000004, MSEloss-0.1223, cindex-0.8561, r2-0.7152, test1: [MSEloss-0.1327, cindex:0.8888, r2:0.7760].pt',
                'paper_performance': {'mse': 0.1327, 'cindex': 0.8888, 'r2': 0.7760}
            },
            {
                'name': 'epoch_1317_fourth',
                'path': 'save/20250725_233313_kiba/model/epoch-1317, LR-0.000012, MSEloss-0.1233, cindex-0.8547, r2-0.7152, test1: [MSEloss-0.1331, cindex:0.8886, r2:0.7775].pt',
                'paper_performance': {'mse': 0.1331, 'cindex': 0.8886, 'r2': 0.7775}
            }
        ]
    
    def load_test_data(self):
        """åŠ è½½æ ‡å‡†åŒ–æµ‹è¯•æ•°æ®"""
        print("ğŸ“Š åŠ è½½KIBAæµ‹è¯•æ•°æ®...")
        
        DATASET = 'kiba'
        fpath = os.path.join('/home/lww/learn_project/MGraphDTA-dev/regression/data', DATASET)
        
        # ç¡®ä¿ä½¿ç”¨ç›¸åŒçš„æ•°æ®åŠ è½½é…ç½®
        test1_set = GNNDataset(fpath, types='test1', use_surface=True, use_masif=True)
        test1_loader = DataLoader(test1_set, batch_size=512, shuffle=False, num_workers=8)
        
        print(f"âœ… æµ‹è¯•é›†å¤§å°: {len(test1_set)} æ ·æœ¬")
        print(f"âœ… æ‰¹æ¬¡å¤§å°: 512")
        print(f"âœ… è¡¨é¢ç‰¹å¾: å¯ç”¨")
        
        return test1_loader
    
    def load_paper_models(self):
        """åŠ è½½è®ºæ–‡ä¸­ä½¿ç”¨çš„æ¨¡å‹"""
        print("ğŸ“¥ åŠ è½½è®ºæ–‡ä¸­çš„æ ‡å‡†æ¨¡å‹...")
        
        models = []
        model_info = []
        
        for config in self.best_models_config:
            if os.path.exists(config['path']):
                try:
                    # ä½¿ç”¨è®ºæ–‡ä¸­çš„æ ‡å‡†æ¨¡å‹é…ç½®
                    model = MGraphDTA(
                        3, 25 + 1,
                        embedding_size=128,
                        filter_num=32,
                        out_dim=1,
                        mask_rate=0.05,
                        temperature=0.1,
                        disable_masking=False,
                        cl_mode='regression',
                        cl_similarity_threshold=0.5,
                        use_surface=True
                    ).to(self.device)
                    
                    # åŠ è½½é¢„è®­ç»ƒæƒé‡
                    state_dict = torch.load(config['path'], map_location=self.device)
                    model.load_state_dict(state_dict)
                    model.eval()
                    
                    models.append(model)
                    model_info.append(config)
                    
                    print(f"âœ… {config['name']} åŠ è½½æˆåŠŸ")
                    
                except Exception as e:
                    print(f"âŒ {config['name']} åŠ è½½å¤±è´¥: {e}")
            else:
                print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {config['name']}")
        
        print(f"ğŸ“Š æˆåŠŸåŠ è½½ {len(models)} ä¸ªæ ‡å‡†æ¨¡å‹")
        return models, model_info
    
    def reproduce_paper_results(self):
        """å¤ç°è®ºæ–‡ä¸­çš„æ ‡å‡†ç»“æœ"""
        print("\nğŸ”¬ å¼€å§‹å¤ç°è®ºæ–‡æ ‡å‡†ç»“æœ...")
        print("=" * 60)
        
        # åŠ è½½æ•°æ®å’Œæ¨¡å‹
        test_loader = self.load_test_data()
        models, model_info = self.load_paper_models()
        
        if len(models) == 0:
            print("âŒ æ— æ³•åŠ è½½ä»»ä½•æ¨¡å‹ï¼Œå¤ç°å¤±è´¥")
            return None
        
        # Step 1: éªŒè¯å•ä¸ªæ¨¡å‹æ€§èƒ½
        print("\n1ï¸âƒ£ éªŒè¯å•ä¸ªæ¨¡å‹æ€§èƒ½...")
        individual_results = []
        individual_predictions = []
        labels = None
        
        for i, (model, info) in enumerate(zip(models, model_info)):
            print(f"   éªŒè¯æ¨¡å‹: {info['name']}")
            
            pred_list = []
            label_list = []
            
            with torch.no_grad():
                for data in test_loader:
                    data = data.to(self.device)
                    pred = model(data)
                    pred_list.append(pred.view(-1).cpu().numpy())
                    if labels is None:
                        label_list.append(data.y.cpu().numpy())
            
            predictions = np.concatenate(pred_list)
            if labels is None:
                labels = np.concatenate(label_list)
            
            # è®¡ç®—æ€§èƒ½
            mse = np.mean((predictions - labels) ** 2)
            cindex = get_cindex(labels, predictions)
            r2 = get_rm2(labels, predictions)
            
            result = {
                'model_name': info['name'],
                'mse': mse,
                'cindex': cindex,
                'r2': r2,
                'paper_mse': info['paper_performance']['mse'],
                'paper_cindex': info['paper_performance']['cindex'],
                'paper_r2': info['paper_performance']['r2']
            }
            
            individual_results.append(result)
            individual_predictions.append(predictions)
            
            print(f"     å®é™…: MSE={mse:.4f}, CI={cindex:.4f}, R2={r2:.4f}")
            print(f"     è®ºæ–‡: MSE={result['paper_mse']:.4f}, CI={result['paper_cindex']:.4f}, R2={result['paper_r2']:.4f}")
        
        # Step 2: å¤ç°é›†æˆç»“æœ
        print("\n2ï¸âƒ£ å¤ç°æ¨¡å‹é›†æˆç»“æœ...")
        
        # ç­‰æƒé‡é›†æˆ (è®ºæ–‡ä¸­ä½¿ç”¨çš„æ–¹æ³•)
        ensemble_pred = np.mean(individual_predictions, axis=0)
        
        ensemble_mse = np.mean((ensemble_pred - labels) ** 2)
        ensemble_cindex = get_cindex(labels, ensemble_pred)
        ensemble_r2 = get_rm2(labels, ensemble_pred)
        
        ensemble_result = {
            'method': 'equal_weight_ensemble',
            'models_used': len(models),
            'mse': ensemble_mse,
            'cindex': ensemble_cindex,
            'r2': ensemble_r2,
            'paper_mse': 0.1321,  # è®ºæ–‡æŠ¥å‘Šçš„é›†æˆç»“æœ
            'paper_cindex': 0.8891,
            'paper_r2': 0.7805
        }
        
        print(f"   å®é™…é›†æˆ: MSE={ensemble_mse:.4f}, CI={ensemble_cindex:.4f}, R2={ensemble_r2:.4f}")
        print(f"   è®ºæ–‡é›†æˆ: MSE={ensemble_result['paper_mse']:.4f}, CI={ensemble_result['paper_cindex']:.4f}, R2={ensemble_result['paper_r2']:.4f}")
        
        # Step 3: å¤ç°æ ¡å‡†ç»“æœ
        print("\n3ï¸âƒ£ å¤ç°é¢„æµ‹æ ¡å‡†ç»“æœ...")
        
        # ä½¿ç”¨äº¤å‰éªŒè¯è¿›è¡ŒIsotonicæ ¡å‡† (è®ºæ–‡ä¸­çš„æ–¹æ³•)
        n_samples = len(ensemble_pred)
        split_idx = n_samples // 2
        
        # è®­ç»ƒæ ¡å‡†å™¨
        train_pred = ensemble_pred[:split_idx]
        train_labels = labels[:split_idx]
        
        calibrator = IsotonicRegression(out_of_bounds='clip')
        calibrator.fit(train_pred, train_labels)
        
        # åº”ç”¨æ ¡å‡†
        calibrated_pred = calibrator.predict(ensemble_pred)
        
        calibrated_mse = np.mean((calibrated_pred - labels) ** 2)
        calibrated_cindex = get_cindex(labels, calibrated_pred)
        calibrated_r2 = get_rm2(labels, calibrated_pred)
        
        calibration_result = {
            'method': 'isotonic_regression',
            'mse': calibrated_mse,
            'cindex': calibrated_cindex,
            'r2': calibrated_r2,
            'paper_mse': 0.1310,  # è®ºæ–‡æŠ¥å‘Šçš„æ ¡å‡†ç»“æœ
            'paper_cindex': 0.8886,
            'paper_r2': 0.8035
        }
        
        print(f"   å®é™…æ ¡å‡†: MSE={calibrated_mse:.4f}, CI={calibrated_cindex:.4f}, R2={calibrated_r2:.4f}")
        print(f"   è®ºæ–‡æ ¡å‡†: MSE={calibration_result['paper_mse']:.4f}, CI={calibration_result['paper_cindex']:.4f}, R2={calibration_result['paper_r2']:.4f}")
        
        # æ±‡æ€»ç»“æœ
        final_results = {
            'reproduction_timestamp': datetime.now().isoformat(),
            'random_seed': 42,
            'device': str(self.device),
            'individual_models': individual_results,
            'ensemble_result': ensemble_result,
            'calibration_result': calibration_result,
            'final_best': {
                'mse': calibrated_mse,
                'cindex': calibrated_cindex,
                'r2': calibrated_r2,
                'method': 'ensemble + isotonic_calibration'
            }
        }
        
        return final_results
    
    def evaluate_reproducibility(self, results):
        """è¯„ä¼°å¯å¤ç°æ€§"""
        print("\nğŸ“Š è¯„ä¼°å¯å¤ç°æ€§...")
        print("=" * 60)
        
        tolerance = {'mse': 0.002, 'cindex': 0.005, 'r2': 0.01}
        
        # è¯„ä¼°æœ€ç»ˆç»“æœ
        final_result = results['calibration_result']
        
        mse_diff = abs(final_result['mse'] - final_result['paper_mse'])
        cindex_diff = abs(final_result['cindex'] - final_result['paper_cindex'])
        r2_diff = abs(final_result['r2'] - final_result['paper_r2'])
        
        mse_ok = mse_diff <= tolerance['mse']
        cindex_ok = cindex_diff <= tolerance['cindex']
        r2_ok = r2_diff <= tolerance['r2']
        
        print(f"MSEå·®å¼‚: {mse_diff:.4f} ({'âœ…' if mse_ok else 'âŒ'} å®¹å·®: Â±{tolerance['mse']:.3f})")
        print(f"CIå·®å¼‚: {cindex_diff:.4f} ({'âœ…' if cindex_ok else 'âŒ'} å®¹å·®: Â±{tolerance['cindex']:.3f})")
        print(f"R2å·®å¼‚: {r2_diff:.4f} ({'âœ…' if r2_ok else 'âŒ'} å®¹å·®: Â±{tolerance['r2']:.3f})")
        
        overall_reproducible = mse_ok and cindex_ok and r2_ok
        
        print(f"\nğŸ¯ æ•´ä½“å¯å¤ç°æ€§: {'âœ… é€šè¿‡' if overall_reproducible else 'âŒ éœ€è¦è°ƒæ•´'}")
        
        return {
            'mse_reproducible': mse_ok,
            'cindex_reproducible': cindex_ok,
            'r2_reproducible': r2_ok,
            'overall_reproducible': overall_reproducible,
            'differences': {
                'mse': mse_diff,
                'cindex': cindex_diff,
                'r2': r2_diff
            }
        }

def main():
    print("ğŸ“‹ KIBAä¼˜åŒ–è®ºæ–‡æ ‡å‡†å¤ç°")
    print("=" * 60)
    print("ç›®æ ‡: å¤ç°è®ºæ–‡ä¸­æŠ¥å‘Šçš„å…³é”®ç»“æœ")
    print("æ–¹æ³•: æ ‡å‡†åŒ–æµç¨‹ + å›ºå®šéšæœºç§å­")
    print("=" * 60)
    
    # è®¾ç½®å¯å¤ç°æ€§
    set_all_seeds(42)
    
    # åˆå§‹åŒ–å¤ç°å™¨
    reproducer = PaperStandardReproduction(device='cpu')
    
    # æ‰§è¡Œæ ‡å‡†å¤ç°
    results = reproducer.reproduce_paper_results()
    
    if results:
        # è¯„ä¼°å¯å¤ç°æ€§
        reproducibility = reproducer.evaluate_reproducibility(results)
        
        # æ·»åŠ å¯å¤ç°æ€§è¯„ä¼°åˆ°ç»“æœä¸­
        results['reproducibility_assessment'] = reproducibility
        
        # ä¿å­˜å®Œæ•´ç»“æœ
        output_file = f"paper_reproduction_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ å®Œæ•´ç»“æœå·²ä¿å­˜: {output_file}")
        
        # ç”Ÿæˆè®ºæ–‡è¡¨æ ¼æ ¼å¼ç»“æœ
        print(f"\nğŸ“Š è®ºæ–‡è¡¨æ ¼æ ¼å¼ç»“æœ:")
        print("-" * 60)
        print("Method                    | MSE    | CI     | R2     |")
        print("-" * 60)
        
        final = results['final_best']
        print(f"Our Method (Ensemble+Cal) | {final['mse']:.4f} | {final['cindex']:.4f} | {final['r2']:.4f} |")
        
        if reproducibility['overall_reproducible']:
            print("\nâœ… ç»“æœå®Œå…¨å¯å¤ç°ï¼Œå¯ä»¥å®‰å…¨ç”¨äºè®ºæ–‡æäº¤ï¼")
        else:
            print("\nâš ï¸ éƒ¨åˆ†ç»“æœå­˜åœ¨å·®å¼‚ï¼Œå»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥")
    
    else:
        print("âŒ å¤ç°å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œç¯å¢ƒé…ç½®")

if __name__ == '__main__':
    main()
