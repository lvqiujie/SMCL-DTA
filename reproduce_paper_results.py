#!/usr/bin/env python3
"""
è®ºæ–‡ç»“æœå¤ç°è„šæœ¬
ç”¨äºéªŒè¯å•æ¨¡å‹è®­ç»ƒçš„å¯å¤ç°æ€§
ç¡®ä¿å…¶ä»–ç ”ç©¶è€…èƒ½å¤Ÿç›´æ¥å¤ç°æˆ‘ä»¬æŠ¥å‘Šçš„ç»“æœ
"""

import os
import torch
import numpy as np
import random
import argparse
import json
from datetime import datetime
from torch_geometric.data import DataLoader

from model_0428_16_dual import MGraphDTA
from dataset import GNNDataset
from metrics import get_cindex, get_rm2

def set_reproducible_seeds(seed=42):
    """è®¾ç½®æ‰€æœ‰éšæœºç§å­ç¡®ä¿å®Œå…¨å¯å¤ç°"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)

class PaperResultsReproducer:
    """è®ºæ–‡ç»“æœå¤ç°å™¨"""
    
    def __init__(self, args):
        self.args = args
        self.device = torch.device(f"cuda:{args.gpu}" if torch.cuda.is_available() else "cpu")
        
        # è®ºæ–‡ä¸­æŠ¥å‘Šçš„é¢„æœŸç»“æœ
        self.paper_results = {
            'mse': 0.1310,
            'cindex': 0.8886,
            'r2': 0.8035,
            'description': 'å•æ¨¡å‹ç»Ÿä¸€è®­ç»ƒç»“æœ'
        }
        
        # å¯æ¥å—çš„å®¹å·®èŒƒå›´
        self.tolerance = {
            'mse': 0.003,    # Â±0.003 MSEå®¹å·®
            'cindex': 0.005, # Â±0.005 CIå®¹å·®  
            'r2': 0.01       # Â±0.01 R2å®¹å·®
        }
        
        print("ğŸ”¬ è®ºæ–‡ç»“æœå¤ç°å™¨åˆå§‹åŒ–")
        print(f"ğŸ“Š é¢„æœŸç»“æœ: MSE={self.paper_results['mse']:.4f}, "
              f"CI={self.paper_results['cindex']:.4f}, R2={self.paper_results['r2']:.4f}")
        print(f"ğŸ“ å®¹å·®èŒƒå›´: MSEÂ±{self.tolerance['mse']:.3f}, "
              f"CIÂ±{self.tolerance['cindex']:.3f}, R2Â±{self.tolerance['r2']:.3f}")
    
    def load_test_data(self):
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        print("ğŸ“Š åŠ è½½KIBAæµ‹è¯•æ•°æ®...")
        
        fpath = os.path.join('/home/lww/learn_project/MGraphDTA-dev/regression/data', self.args.dataset)
        test1_set = GNNDataset(fpath, types='test1', use_surface=True, use_masif=True)
        
        self.test_loader = DataLoader(
            test1_set, 
            batch_size=512, 
            shuffle=False, 
            num_workers=8
        )
        
        print(f"âœ… æµ‹è¯•é›†å¤§å°: {len(test1_set)} æ ·æœ¬")
        print(f"âœ… è¡¨é¢ç‰¹å¾: å¯ç”¨")
    
    def load_trained_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print("ğŸ“¥ åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
        
        # åˆ›å»ºæ¨¡å‹æ¶æ„
        self.model = MGraphDTA(
            3, 25 + 1,
            embedding_size=128,
            filter_num=32,
            out_dim=1,
            mask_rate=0.05,
            temperature=0.1,
            disable_masking=False,
            cl_mode='regression',
            cl_similarity_threshold=0.5,
            use_surface=True
        ).to(self.device)
        
        # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹æ–‡ä»¶
        model_files = [f for f in os.listdir('.') if f.startswith('best_single_model_') and f.endswith('.pt')]
        
        if not model_files:
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
            print("ğŸ’¡ è¯·å…ˆè¿è¡Œ: python train_kiba_single_model.py --save_model")
            return False
        
        # é€‰æ‹©æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶
        latest_model = max(model_files, key=os.path.getctime)
        
        try:
            state_dict = torch.load(latest_model, map_location=self.device)
            self.model.load_state_dict(state_dict)
            self.model.eval()
            
            print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {latest_model}")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def evaluate_model(self):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print("ğŸ§ª è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        
        pred_list = []
        label_list = []
        
        with torch.no_grad():
            for batch_idx, data in enumerate(self.test_loader):
                data = data.to(self.device)
                pred = self.model(data)
                pred_list.append(pred.view(-1).cpu().numpy())
                label_list.append(data.y.cpu().numpy())
                
                # æ˜¾ç¤ºè¿›åº¦
                if batch_idx % 10 == 0:
                    print(f"   å¤„ç†æ‰¹æ¬¡ {batch_idx+1}/{len(self.test_loader)}")
        
        predictions = np.concatenate(pred_list)
        labels = np.concatenate(label_list)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        mse = np.mean((predictions - labels) ** 2)
        cindex = get_cindex(labels, predictions)
        r2 = get_rm2(labels, predictions)
        
        results = {
            'mse': mse,
            'cindex': cindex,
            'r2': r2,
            'predictions': predictions.tolist(),
            'labels': labels.tolist()
        }
        
        print(f"ğŸ“Š å®é™…ç»“æœ: MSE={mse:.4f}, CI={cindex:.4f}, R2={r2:.4f}")
        
        return results
    
    def compare_with_paper(self, actual_results):
        """ä¸è®ºæ–‡ç»“æœå¯¹æ¯”"""
        print("\nğŸ“Š ä¸è®ºæ–‡ç»“æœå¯¹æ¯”:")
        print("=" * 60)
        
        comparisons = {}
        all_within_tolerance = True
        
        for metric in ['mse', 'cindex', 'r2']:
            paper_value = self.paper_results[metric]
            actual_value = actual_results[metric]
            diff = abs(actual_value - paper_value)
            tolerance = self.tolerance[metric]
            within_tolerance = diff <= tolerance
            
            comparisons[metric] = {
                'paper': paper_value,
                'actual': actual_value,
                'difference': diff,
                'tolerance': tolerance,
                'within_tolerance': within_tolerance,
                'relative_error': (diff / paper_value) * 100
            }
            
            status = "âœ… é€šè¿‡" if within_tolerance else "âŒ è¶…å‡ºå®¹å·®"
            rel_error = comparisons[metric]['relative_error']
            
            print(f"{metric.upper():>6}: è®ºæ–‡={paper_value:.4f}, "
                  f"å®é™…={actual_value:.4f}, å·®å¼‚={diff:.4f} ({rel_error:.1f}%), {status}")
            
            if not within_tolerance:
                all_within_tolerance = False
        
        print("=" * 60)
        
        if all_within_tolerance:
            print("ğŸ‰ æ‰€æœ‰æŒ‡æ ‡éƒ½åœ¨å¯æ¥å—å®¹å·®èŒƒå›´å†…ï¼")
            print("âœ… è®ºæ–‡ç»“æœå®Œå…¨å¯å¤ç°ï¼")
        else:
            print("âš ï¸ éƒ¨åˆ†æŒ‡æ ‡è¶…å‡ºå®¹å·®èŒƒå›´")
            print("ğŸ’¡ å»ºè®®æ£€æŸ¥ç¯å¢ƒé…ç½®æˆ–é‡æ–°è®­ç»ƒ")
        
        return comparisons, all_within_tolerance
    
    def generate_report(self, actual_results, comparisons, reproducible):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report = {
            'reproduction_info': {
                'timestamp': datetime.now().isoformat(),
                'seed': self.args.seed,
                'device': str(self.device),
                'dataset': self.args.dataset
            },
            'paper_results': self.paper_results,
            'actual_results': {k: v for k, v in actual_results.items() if k != 'predictions' and k != 'labels'},
            'comparisons': comparisons,
            'reproducibility': {
                'overall_success': reproducible,
                'tolerance_used': self.tolerance
            },
            'recommendations': []
        }
        
        # æ·»åŠ å»ºè®®
        if reproducible:
            report['recommendations'].extend([
                "âœ… ç»“æœå®Œå…¨å¯å¤ç°ï¼Œå¯ä»¥å®‰å…¨ç”¨äºè®ºæ–‡æäº¤",
                "ğŸ“Š æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡éƒ½åœ¨é¢„æœŸèŒƒå›´å†…",
                "ğŸ¯ å•æ¨¡å‹æ–¹æ³•æˆåŠŸè¾¾åˆ°ç›®æ ‡æ€§èƒ½"
            ])
        else:
            report['recommendations'].extend([
                "âš ï¸ éƒ¨åˆ†ç»“æœå­˜åœ¨å·®å¼‚ï¼Œå»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥",
                "ğŸ”§ ç¡®ä¿ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­å’Œç¯å¢ƒé…ç½®",
                "ğŸ’¡ å¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæˆ–è°ƒæ•´è¶…å‚æ•°"
            ])
        
        return report
    
    def reproduce(self):
        """æ‰§è¡Œå®Œæ•´çš„å¤ç°æµç¨‹"""
        print("ğŸš€ å¼€å§‹è®ºæ–‡ç»“æœå¤ç°...")
        print("=" * 60)
        
        # åŠ è½½æ•°æ®
        self.load_test_data()
        
        # åŠ è½½æ¨¡å‹
        if not self.load_trained_model():
            return None
        
        # è¯„ä¼°æ€§èƒ½
        actual_results = self.evaluate_model()
        
        # ä¸è®ºæ–‡ç»“æœå¯¹æ¯”
        comparisons, reproducible = self.compare_with_paper(actual_results)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report(actual_results, comparisons, reproducible)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"reproduction_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # æ‰“å°æ€»ç»“
        print(f"\nğŸ¯ å¤ç°æ€»ç»“:")
        print(f"   ç¯å¢ƒéªŒè¯: âœ…")
        print(f"   æ¨¡å‹åŠ è½½: âœ…")
        print(f"   æ€§èƒ½è¯„ä¼°: âœ…")
        print(f"   ç»“æœå¯¹æ¯”: {'âœ… æˆåŠŸ' if reproducible else 'âŒ éƒ¨åˆ†å¤±è´¥'}")
        print(f"   æ•´ä½“å¯å¤ç°æ€§: {'âœ… é€šè¿‡' if reproducible else 'âŒ éœ€è¦è°ƒæ•´'}")
        
        return report

def main():
    parser = argparse.ArgumentParser(description='è®ºæ–‡ç»“æœå¤ç°éªŒè¯')
    parser.add_argument('--dataset', type=str, default='kiba', help='æ•°æ®é›†åç§°')
    parser.add_argument('--gpu', type=int, default=0, help='GPUè®¾å¤‡å·')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    
    args = parser.parse_args()
    
    # è®¾ç½®å¯å¤ç°æ€§
    set_reproducible_seeds(args.seed)
    
    print("ğŸ“‹ KIBAè®ºæ–‡ç»“æœå¤ç°éªŒè¯")
    print("=" * 60)
    print("ç›®æ ‡: éªŒè¯å•æ¨¡å‹è®­ç»ƒç»“æœçš„å¯å¤ç°æ€§")
    print("æ–¹æ³•: åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶è¯„ä¼°æ€§èƒ½")
    print("=" * 60)
    
    # åˆ›å»ºå¤ç°å™¨å¹¶æ‰§è¡Œ
    reproducer = PaperResultsReproducer(args)
    report = reproducer.reproduce()
    
    if report and report['reproducibility']['overall_success']:
        print("\nğŸ‰ æ­å–œï¼è®ºæ–‡ç»“æœå®Œå…¨å¯å¤ç°ï¼")
        print("ğŸ“Š å¯ä»¥å®‰å…¨åœ°åœ¨è®ºæ–‡ä¸­æŠ¥å‘Šè¿™äº›ç»“æœ")
    elif report:
        print("\nâš ï¸ å¤ç°è¿‡ç¨‹å®Œæˆï¼Œä½†éƒ¨åˆ†ç»“æœå­˜åœ¨å·®å¼‚")
        print("ğŸ’¡ è¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Šäº†è§£å…·ä½“æƒ…å†µ")
    else:
        print("\nâŒ å¤ç°å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œç¯å¢ƒé…ç½®")

if __name__ == '__main__':
    main()
